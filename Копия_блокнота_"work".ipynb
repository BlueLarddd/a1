{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BlueLarddd/a1/blob/main/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%22work%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBn5Wu0YSwwi"
      },
      "source": [
        "# Скачиваем нужные библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zknD7NPZaLPM",
        "outputId": "36e1f633-12a2-4eec-8f77-35a21ccf5538"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting patool\n",
            "  Downloading patool-2.0.0-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.7/93.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-2.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install patool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4xrRghMajKU",
        "outputId": "01c27ad3-c959-4032-c080-bbf132bae239"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install matplotlib opencv-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juJmh8m8S_O1"
      },
      "source": [
        "# Загружаем датасет"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOg4v4pdaOBV",
        "outputId": "817410b4-d2f8-4bfc-cc39-42dc674a75fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO patool: Extracting /content/symbols.rar ...\n",
            "INFO:patool:Extracting /content/symbols.rar ...\n",
            "INFO patool: running /usr/bin/unrar x -- /content/symbols.rar\n",
            "INFO:patool:running /usr/bin/unrar x -- /content/symbols.rar\n",
            "INFO patool:     with cwd='/content/extracted/', input=''\n",
            "INFO:patool:    with cwd='/content/extracted/', input=''\n",
            "INFO patool: ... /content/symbols.rar extracted to `/content/extracted/'.\n",
            "INFO:patool:... /content/symbols.rar extracted to `/content/extracted/'.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from urllib.parse import urlencode\n",
        "import patoolib\n",
        "import os\n",
        "\n",
        "base_url = 'https://cloud-api.yandex.net/v1/disk/public/resources/download?'\n",
        "public_key = 'https://disk.yandex.ru/d/5cV2jxYlKA3GCQ'\n",
        "\n",
        "# Получаем загрузочную ссылку\n",
        "final_url = base_url + urlencode(dict(public_key=public_key))\n",
        "response = requests.get(final_url)\n",
        "download_url = response.json()['href']\n",
        "\n",
        "# Загружаем файл и сохраняем его\n",
        "download_response = requests.get(download_url)\n",
        "downloaded_file_path = '/content/symbols.rar'\n",
        "\n",
        "with open(downloaded_file_path, 'wb') as f:\n",
        "    f.write(download_response.content)\n",
        "\n",
        "# Разархивируем файл\n",
        "extracted_path = '/content/extracted/'\n",
        "\n",
        "# Проверяем, существует ли папка для распаковки, и создаем ее при необходимости\n",
        "if not os.path.exists(extracted_path):\n",
        "    os.makedirs(extracted_path)\n",
        "\n",
        "# Распаковываем скачанный архив\n",
        "patoolib.extract_archive(downloaded_file_path, outdir=extracted_path)\n",
        "\n",
        "# Удаляем изначальный архив\n",
        "os.remove(downloaded_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rDi3h3eaS3c"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CusRbDLGaVa8"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(image_path):\n",
        "    # Загрузка изображения\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    # Изменение размера изображения\n",
        "    img = cv2.resize(img, (32, 32))\n",
        "\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFOJlc_UaWEs"
      },
      "outputs": [],
      "source": [
        "def show_images(original, preprocessed, title1='Original Image', title2='Preprocessed Image'):\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(original, cmap='gray')\n",
        "    plt.title(title1)\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(preprocessed, cmap='gray')\n",
        "    plt.title(title2)\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdpFQao0TM9A"
      },
      "source": [
        "# Находим объект на изображении"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_mnS-2baYWc"
      },
      "outputs": [],
      "source": [
        "def resize_and_center_crop(image_path, target_size=(55, 55)):\n",
        "    # Загрузка изображения\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # Применение адаптивного выравнивания гистограммы или других шагов предобработки по желанию\n",
        "    # ...\n",
        "\n",
        "    # Применение фильтра для выделения контуров\n",
        "    edged = cv2.Canny(img, threshold1=30, threshold2=100)\n",
        "\n",
        "    # Нахождение контуров в изображении\n",
        "    contours, _ = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    if contours:\n",
        "        # Выбираем самый большой контур\n",
        "        largest_contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "        # Получаем ограничивающий прямоугольник вокруг контура\n",
        "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
        "\n",
        "        # Рассчитываем центр ограничивающего прямоугольника\n",
        "        center_x = x + w // 2\n",
        "        center_y = y + h // 2\n",
        "\n",
        "        # Рассчитываем координаты для обрезки изображения\n",
        "        left = max(0, center_x - target_size[0] // 2)\n",
        "        top = max(0, center_y - target_size[1] // 2)\n",
        "        right = min(img.shape[1], center_x + target_size[0] // 2)\n",
        "        bottom = min(img.shape[0], center_y + target_size[1] // 2)\n",
        "\n",
        "        # Обрезаем изображение согласно координатам\n",
        "        cropped_img = img[top:bottom, left:right]\n",
        "\n",
        "        # Нормализация значений пикселей\n",
        "        cropped_img = cropped_img / 255.0\n",
        "\n",
        "        # Изменение размера до целевых размеров\n",
        "        cropped_img = cv2.resize(cropped_img, target_size, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "        return cropped_img\n",
        "\n",
        "    else:\n",
        "        print(f\"Контуры не найдены {image_path}.\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "H8i4tmCwc_PE",
        "outputId": "91ba0f8d-cf69-482f-eb0d-1f251f5aa4c8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(55, 55)\n"
          ]
        }
      ],
      "source": [
        "image_path = \"/content/extracted/3/15.bmp\"\n",
        "cropped_image = resize_and_center_crop(image_path)\n",
        "\n",
        "# Вывод оригинального и обрезанного изображений\n",
        "show_images(cv2.imread(image_path, cv2.IMREAD_GRAYSCALE), cropped_image)\n",
        "\n",
        "print(cropped_image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw3Cw5LdeL0O"
      },
      "source": [
        "# Кропаем все фото в датасете"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krH7RBW_eOCl",
        "outputId": "c061a771-430b-41df-edaf-6bc0aac925b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Контуры не найдены /content/extracted/negative/_694.bmp.\n",
            "Контуры не найдены /content/extracted/negative/_585.bmp.\n",
            "Контуры не найдены /content/extracted/negative/_763.bmp.\n",
            "Контуры не найдены /content/extracted/negative/23113418.bmp.\n",
            "Контуры не найдены /content/extracted/negative/_610.bmp.\n",
            "Контуры не найдены /content/extracted/negative/_685.bmp.\n",
            "Контуры не найдены /content/extracted/negative/14912346.bmp.\n",
            "Контуры не найдены /content/extracted/negative/415 (2).bmp.\n",
            "Контуры не найдены /content/extracted/negative/_496.bmp.\n",
            "Контуры не найдены /content/extracted/negative/355.bmp.\n",
            "Контуры не найдены /content/extracted/negative/_589.bmp.\n",
            "Контуры не найдены /content/extracted/negative/_422.bmp.\n",
            "Контуры не найдены /content/extracted/negative/25313517.bmp.\n",
            "Контуры не найдены /content/extracted/negative/33613731.bmp.\n",
            "Контуры не найдены /content/extracted/negative/_707.bmp.\n",
            "Контуры не найдены /content/extracted/negative/23713433.bmp.\n",
            "Контуры не найдены /content/extracted/negative/1501242.bmp.\n",
            "Контуры не найдены /content/extracted/negative/_692.bmp.\n",
            "Контуры не найдены /content/extracted/negative/_95.bmp.\n",
            "Контуры не найдены /content/extracted/negative/_308.bmp.\n",
            "Контуры не найдены /content/extracted/negative/_698.bmp.\n",
            "Контуры не найдены /content/extracted/negative/_93.bmp.\n",
            "Контуры не найдены /content/extracted/negative/_587.bmp.\n",
            "Контуры не найдены /content/extracted/negative/_611.bmp.\n",
            "Контуры не найдены /content/extracted/negative/_342.bmp.\n",
            "Контуры не найдены /content/extracted/negative/_702.bmp.\n"
          ]
        }
      ],
      "source": [
        "# Папка, где хранятся изображения\n",
        "base_folder = \"/content/extracted\"\n",
        "\n",
        "# Функция для обрезки и перезаписи изображений\n",
        "def process_images(folder_path):\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        if os.path.isfile(file_path):\n",
        "            # Игнорируем файлы, не являющиеся изображениями\n",
        "            if not filename.lower().endswith(('.bmp')):\n",
        "                continue\n",
        "\n",
        "            # Обрезаем изображение\n",
        "            cropped_image = resize_and_center_crop(file_path)\n",
        "\n",
        "            if cropped_image is not None:\n",
        "                # Перезаписываем изображение в оригинальную папку\n",
        "                cv2.imwrite(file_path, cropped_image * 255)  # Умножаем на 255 для сохранения в формате изображения (0-255)\n",
        "\n",
        "# Перебираем все папки в базовой папке\n",
        "for subfolder in os.listdir(base_folder):\n",
        "    subfolder_path = os.path.join(base_folder, subfolder)\n",
        "\n",
        "    if os.path.isdir(subfolder_path):\n",
        "        # Обрабатываем изображения в каждой подпапке\n",
        "        process_images(subfolder_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2z4vRF6tihpD"
      },
      "source": [
        "# Архитектура нейронки для распознавания символов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ite3JgDifzz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "953d2cfa-9718-4eb3-ff20-14873089dff9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBQk6wpfingU"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self, num_classes=22):\n",
        "        super(CustomCNN, self).__init__()\n",
        "\n",
        "        # Сверточные слои\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # Слои объединения (pooling)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        # Полносвязанные слои\n",
        "        self.fc1 = nn.Linear(128 * 6 * 6, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Проход через сверточные слои\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "\n",
        "        # Разворачиваем тензор перед подачей на полносвязанные слои\n",
        "        x = x.view(-1, 128 * 6 * 6)\n",
        "\n",
        "        # Проход через полносвязанные слои\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Инициализация модели\n",
        "model = CustomCNN()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKn1D-qbi5zd"
      },
      "source": [
        "# Загрузчик данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdZKt2Zpk4TR"
      },
      "outputs": [],
      "source": [
        "!cd  /content/extracted && rm -rf `find -type d -name .ipynb_checkpoints`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNzUw8doi7UG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Предполагается, что ваш датасет находится в папке 'extracted'\n",
        "dataset_path = '/content/extracted'\n",
        "\n",
        "# Задаем преобразования для изображений\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.Resize((55, 55)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Создаем DataLoader для обучающего датасета\n",
        "train_dataset = ImageFolder(dataset_path, transform=transform)\n",
        "\n",
        "# Добавим преобразование для получения меток в виде числовых значений\n",
        "class_to_idx = train_dataset.class_to_idx\n",
        "idx_to_class = {i: class_name for class_name, i in class_to_idx.items()}\n",
        "\n",
        "# Разделим датасет на обучающую и валидационную выборки\n",
        "train_indices, val_indices = train_test_split(list(range(len(train_dataset))), test_size=0.2, random_state=42)\n",
        "\n",
        "train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
        "val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, sampler=train_sampler)\n",
        "val_loader = DataLoader(train_dataset, batch_size=32, sampler=val_sampler)\n",
        "\n",
        "# Определяем функцию потерь и оптимизатор\n",
        "model = CustomCNN(num_classes=len(class_to_idx))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gv6VpzHneni"
      },
      "source": [
        "# Обучение и валидация модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2FrGDI4neMy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "946ad3ba-9b8b-46d0-d648-b4b87451cd9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Train Loss: 0.31213229898552025\n",
            "Epoch 1/3, Validation Loss: 0.10524680902217996, Accuracy: 97.27615965480044%\n",
            "Epoch 2/3, Train Loss: 0.08665610004510231\n",
            "Epoch 2/3, Validation Loss: 0.10140337742431539, Accuracy: 97.6537216828479%\n",
            "Epoch 3/3, Train Loss: 0.05645612324992569\n",
            "Epoch 3/3, Validation Loss: 0.06904805285288101, Accuracy: 98.35490830636462%\n"
          ]
        }
      ],
      "source": [
        "# Обучение модели\n",
        "num_epochs = 3\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Передаем изображения в нейронную сеть\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Вычисляем функцию потерь\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Обратное распространение и оптимизация\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {total_loss/len(train_loader)}')\n",
        "\n",
        "    # Валидация модели\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            # Передаем изображения в нейронную сеть\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Вычисляем функцию потерь\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss/len(val_loader)}, Accuracy: {100 * correct / total}%')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3377DIXTSejt"
      },
      "source": [
        "# Сохраняем весовые коэффициенты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cD08iTtRJYkg"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), '/content/weights.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B87EvX8hSr2y"
      },
      "source": [
        "# Проверка работоспособности"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-aowZ9EJk6-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "497b9727-e36a-483a-cbab-5738611c9014"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-37356485b2c8>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Пример использования\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/A.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mpredicted_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'The predicted class is: {predicted_class}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-37356485b2c8>\u001b[0m in \u001b[0;36mpredict_image\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Загрузка изображения и применение трансформаций\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 'L' означает оттенки серого\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     transform = transforms.Compose([\n\u001b[1;32m      8\u001b[0m         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m55\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m55\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3227\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3228\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/A.jpg'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def predict_image(image_path):\n",
        "    # Загрузка изображения и применение трансформаций\n",
        "    image = Image.open(image_path).convert('L')  # 'L' означает оттенки серого\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((55, 55)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    image = transform(image).unsqueeze(0)  # Добавляем размерность батча\n",
        "\n",
        "    # Переводим модель в режим оценки (не обучения)\n",
        "    model.eval()\n",
        "\n",
        "    # Передаем изображение в модель для предсказания\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "\n",
        "    # Получаем предсказанный класс\n",
        "    _, predicted_class = torch.max(output, 1)\n",
        "\n",
        "    # Возвращаем название класса\n",
        "    predicted_class_name = idx_to_class[predicted_class.item()]\n",
        "\n",
        "    # Преобразуем тензор изображения обратно в изображение\n",
        "    image_np = np.array(image.squeeze(0).permute(1, 2, 0))\n",
        "    image_np = np.clip(image_np, 0, 1)  # Ограничиваем значения пикселей от 0 до 1\n",
        "    # Выводим изображение и результат\n",
        "    plt.imshow(image_np, cmap='gray')\n",
        "    plt.title(f'Predicted Class: {predicted_class_name}')\n",
        "    plt.show()\n",
        "\n",
        "# Пример использования\n",
        "image_path = '/content/A.jpg'\n",
        "predicted_class = predict_image(image_path)\n",
        "print(f'The predicted class is: {predicted_class}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiaIu7fpbUP-"
      },
      "source": [
        "Средний размер изображения в датасете"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeEkzBxbcmWA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "def find_average_image_size(dataset_path):\n",
        "    total_width = 0\n",
        "    total_height = 0\n",
        "    num_images = 0\n",
        "\n",
        "    # Проход по всем изображениям в директории датасета\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "        for file in files:\n",
        "            if file.endswith(('.bmp', '.jpg', '.jpeg')):\n",
        "                # Формируем полный путь к изображению\n",
        "                image_path = os.path.join(root, file)\n",
        "\n",
        "                # Загружаем изображение и получаем его размеры\n",
        "                img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "                height, width = img.shape[:2]\n",
        "\n",
        "                # Обновляем суммы размеров\n",
        "                total_width += width\n",
        "                total_height += height\n",
        "                num_images += 1\n",
        "\n",
        "    # Вычисляем средние размеры\n",
        "    if num_images > 0:\n",
        "        average_width = total_width / num_images\n",
        "        average_height = total_height / num_images\n",
        "        return average_width, average_height\n",
        "    else:\n",
        "        return 0, 0\n",
        "\n",
        "# Пример использования:\n",
        "dataset_path = \"/content/extracted\"\n",
        "average_width, average_height = find_average_image_size(dataset_path)\n",
        "\n",
        "print(f\"Средние размеры изображений в датасете: {average_width} x {average_height}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSgbFYwZT5or"
      },
      "source": [
        "# Наша предобученная модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8RxIFQpT-Xb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "# путь к файлу с весами модели\n",
        "weights_path = '/content/weights.pth'\n",
        "\n",
        "# экземпляр модели с аналогичной архитектурой\n",
        "loaded_model = CustomCNN()\n",
        "\n",
        "# загружаем веса\n",
        "loaded_model.load_state_dict(torch.load(weights_path))\n",
        "\n",
        "# переводим модель в режим оценки\n",
        "loaded_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjsGJdPgUoF6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def predict_image(image_path):\n",
        "    # Загрузка изображения и применение трансформаций\n",
        "    image = Image.open(image_path).convert('L')  # 'L' означает оттенки серого\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((55, 55)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    image = transform(image).unsqueeze(0)  # Добавляем размерность батча\n",
        "\n",
        "    # Переводим модель в режим оценки (не обучения)\n",
        "    loaded_model.eval()\n",
        "\n",
        "    # Передаем изображение в модель для предсказания\n",
        "    with torch.no_grad():\n",
        "        output = loaded_model(image)\n",
        "\n",
        "    # Получаем предсказанный класс\n",
        "    _, predicted_class = torch.max(output, 1)\n",
        "\n",
        "    # Возвращаем название класса\n",
        "    predicted_class_name = idx_to_class[predicted_class.item()]\n",
        "\n",
        "    # Преобразуем тензор изображения обратно в изображение\n",
        "    image_np = np.array(image.squeeze(0).permute(1, 2, 0))\n",
        "    image_np = np.clip(image_np, 0, 1)  # Ограничиваем значения пикселей от 0 до 1\n",
        "    # Выводим изображение и результат\n",
        "    plt.imshow(image_np, cmap='gray')\n",
        "    plt.title(f'Predicted Class: {predicted_class_name}')\n",
        "    plt.show()\n",
        "\n",
        "# Пример использования\n",
        "image_path = '/content/A.jpg'\n",
        "predicted_class = predict_image(image_path)\n",
        "print(f'The predicted class is: {predicted_class}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Выделение номера авто на изображении"
      ],
      "metadata": {
        "id": "Uq6KId3c06v_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def detecting_plate(image_path, new_path):\n",
        "  # Загрузка изображения\n",
        "  image = cv2.imread(image_path)\n",
        "\n",
        "  # Загрузка предварительно обученного детектора\n",
        "  cascade_path = '/content/haarcascade_russian_plate_number.xml'\n",
        "  plate_cascade = cv2.CascadeClassifier(cascade_path)\n",
        "\n",
        "  # Преобразование в оттенки серого\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  # Детекция номера\n",
        "  plates = plate_cascade.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=7, minSize=(30, 30))\n",
        "\n",
        "  # Находим самый большой номер\n",
        "  largest_plate = None\n",
        "  largest_area = 0\n",
        "\n",
        "  for (x, y, w, h) in plates:\n",
        "      # Вычисляем площадь\n",
        "      area = w * h\n",
        "\n",
        "      # Если текущий номер больше предыдущего самого большого\n",
        "      if area > largest_area:\n",
        "          largest_area = area\n",
        "          largest_plate = (x, y, w, h)\n",
        "\n",
        "  # Если найден номер, обрезаем изображение\n",
        "  if largest_plate is not None:\n",
        "      x, y, w, h = largest_plate\n",
        "      cropped_plate = image[y:y+h, x:x+w]\n",
        "\n",
        "      # Преобразование в оттенки серого\n",
        "      gray_cropped = cv2.cvtColor(cropped_plate, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "      # Применение адаптивной бинаризации\n",
        "      _, thresh = cv2.threshold(gray_cropped, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "      # Применение морфологических операций\n",
        "      kernel = np.ones((5, 5), np.uint8)\n",
        "      thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
        "      thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "      # Детекция контуров\n",
        "      contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "      # Находим контур с максимальной длиной\n",
        "      largest_contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "      # Находим прямоугольник, описывающий контур\n",
        "      rect = cv2.minAreaRect(largest_contour)\n",
        "      box = cv2.boxPoints(rect)\n",
        "      box = np.int0(box)\n",
        "\n",
        "      # Поворачиваем и наклоняем изображение для выравнивания номера\n",
        "      width, height = int(rect[1][0]), int(rect[1][1])\n",
        "      src_pts = box.astype(\"float32\")\n",
        "      dst_pts = np.array([[0, height-1], [0, 0], [width-1, 0], [width-1, height-1]], dtype=\"float32\")\n",
        "\n",
        "      # Получаем матрицу преобразования и применяем ее\n",
        "      M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
        "      corrected_plate = cv2.warpPerspective(cropped_plate, M, (width, height))\n",
        "      if width < height:\n",
        "        corrected_plate = cv2.rotate(corrected_plate, cv2.ROTATE_90_CLOCKWISE)\n",
        "      if width != 250 and height != 65:\n",
        "        corrected_plate = cv2.resize(corrected_plate, (250, 65))\n",
        "      # Выводим изображение с выровненным номером\n",
        "      # cv2_imshow(corrected_plate)\n",
        "      cv2.imwrite(new_path, corrected_plate)\n",
        "      # cv2.waitKey(0)\n",
        "      # cv2.destroyAllWindows()\n",
        "  else:\n",
        "      print('Номер не обнаружен.')"
      ],
      "metadata": {
        "id": "-ZIoFku98bna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Разделение номера на основную часть и регион"
      ],
      "metadata": {
        "id": "jx-If8cDC5I8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def split_plate(image_path):\n",
        "  # Загрузка изображения с выровненным номером\n",
        "  corrected_plate = cv2.imread(image_path)\n",
        "\n",
        "  # Получаем размеры изображения\n",
        "  height, width, _ = corrected_plate.shape\n",
        "\n",
        "  # Процентное соотношение разделения\n",
        "  percentage_split = 75.5\n",
        "  percentage_bottom_cut = 42\n",
        "\n",
        "  # Вычисляем границы разделения\n",
        "  split_point = int(width * (percentage_split / 100))\n",
        "\n",
        "  # Вырезаем и выводим две части\n",
        "  first_part = corrected_plate[:, :split_point]\n",
        "  second_part = corrected_plate[:, split_point:]\n",
        "\n",
        "  # Вычисляем высоту второй части\n",
        "  height_second_part = second_part.shape[0]\n",
        "\n",
        "  # Вычисляем количество пикселей, которые нужно обрезать снизу\n",
        "  cut_pixels = int(height_second_part * (percentage_bottom_cut / 100))\n",
        "\n",
        "  # Обрезаем 20% снизу от второй части\n",
        "  second_part_cropped = second_part[:-cut_pixels, :]\n",
        "\n",
        "  return first_part, second_part_cropped\n",
        "\n"
      ],
      "metadata": {
        "id": "ZEgaOFpRsNHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Вычленение символов"
      ],
      "metadata": {
        "id": "3FHb70r3C-Tt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Функция для выделения символов на изображении\n",
        "def extract_characters(image):\n",
        "    # Преобразование в оттенки серого\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Применение адаптивной бинаризации для выделения символов\n",
        "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Нахождение контуров символов\n",
        "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Сортировка контуров по X-координате\n",
        "    contours = sorted(contours, key=lambda x: cv2.boundingRect(x)[0])\n",
        "\n",
        "    # Итерация по контурам и выделение каждого символа с белым фоном\n",
        "    characters = []\n",
        "    for contour in contours:\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "        # Исключение слишком маленьких символов (можно настроить)\n",
        "        if w > 10 and h > 10:\n",
        "            # Вырезаем символ с добавлением белого фона\n",
        "            symbol_with_background = 255 * np.ones((h + 10, w + 10, 3), dtype=np.uint8)\n",
        "            symbol_with_background[5:5+h, 5:5+w, :] = image[y:y+h, x:x+w, :]\n",
        "\n",
        "            characters.append(symbol_with_background)\n",
        "\n",
        "    return characters\n",
        "\n",
        "\n",
        "def split_symbols(plate_path, first_path, second_path):\n",
        "\n",
        "  first_part, second_part_cropped = split_plate(plate_path)\n",
        "  # Выделение символов для первой и второй частей\n",
        "  characters_first_part = extract_characters(first_part)\n",
        "  characters_second_part = extract_characters(second_part_cropped)\n",
        "\n",
        "  save_path_first_part = first_path\n",
        "  save_path_second_part = second_path\n",
        "\n",
        "  # Создание папок, если они не существуют\n",
        "  os.makedirs(save_path_first_part, exist_ok=True)\n",
        "  os.makedirs(save_path_second_part, exist_ok=True)\n",
        "\n",
        "  # Сохранение изображений символов\n",
        "  for i, character in enumerate(characters_first_part, start=1):\n",
        "      save_filename = os.path.join(save_path_first_part, f\"character_{i}.png\")\n",
        "      cv2.imwrite(save_filename, character)\n",
        "\n",
        "  for i, character in enumerate(characters_second_part, start=1):\n",
        "      save_filename = os.path.join(save_path_second_part, f\"character_{i}.png\")\n",
        "      cv2.imwrite(save_filename, character)\n",
        "\n",
        "  cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "DwHTuCcVz06X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Предсказания"
      ],
      "metadata": {
        "id": "3yPNlla6DKAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def predict_image(image_path):\n",
        "    # Загрузка изображения и применение трансформаций\n",
        "    image = Image.open(image_path).convert('L')  # 'L' означает оттенки серого\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((55, 55)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    image = transform(image).unsqueeze(0)  # Добавляем размерность батча\n",
        "\n",
        "    # Переводим модель в режим оценки (не обучения)\n",
        "    loaded_model.eval()\n",
        "\n",
        "    # Передаем изображение в модель для предсказания\n",
        "    with torch.no_grad():\n",
        "        output = loaded_model(image)\n",
        "\n",
        "    # Получаем предсказанный класс\n",
        "    _, predicted_class = torch.max(output, 1)\n",
        "\n",
        "    # Возвращаем название класса\n",
        "    predicted_class_name = idx_to_class[predicted_class.item()]\n",
        "\n",
        "    # Преобразуем тензор изображения обратно в изображение\n",
        "    image_np = np.array(image.squeeze(0).permute(1, 2, 0))\n",
        "    image_np = np.clip(image_np, 0, 1)  # Ограничиваем значения пикселей от 0 до 1\n",
        "    # Выводим изображение и результат\n",
        "    # plt.imshow(image_np, cmap='gray')\n",
        "    # plt.title(f'Predicted Class: {predicted_class_name}')\n",
        "    # plt.show()\n",
        "    if predicted_class_name == 'negative':\n",
        "      predicted_class_name = ''\n",
        "    return predicted_class_name\n",
        "\n",
        "# Пример использования\n",
        "# image_path = '/content/first_part/character_2.png'\n",
        "# predicted_class = predict_image(image_path)\n",
        "# print(f'The predicted class is: {predicted_class}')"
      ],
      "metadata": {
        "id": "lG4u7R2i6vW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Соединяем всё вместе"
      ],
      "metadata": {
        "id": "ZyY1jptxJAJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#функция удаления файлов в папке\n",
        "def delete_files_in_folder(folder_path):\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        try:\n",
        "            if os.path.isfile(file_path):\n",
        "                os.remove(file_path)\n",
        "        except Exception as e:\n",
        "            print(f'Ошибка при удалении файла {file_path}. {e}')"
      ],
      "metadata": {
        "id": "1d9IDZ-oTbQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_predictions(folder_path):\n",
        "  prediction = []\n",
        "  for filename in sorted(os.listdir(folder_path)):\n",
        "    image_path = os.path.join(folder_path, filename)\n",
        "    symbol = predict_image(image_path)\n",
        "    prediction.append(symbol)\n",
        "\n",
        "  return prediction"
      ],
      "metadata": {
        "id": "6jrZnlUzNU8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kKcwVgr1RqJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_path = '/content/corrected_plate.jpg'\n",
        "image_path = '/content/car3.jpg'\n",
        "first_path = '/content/first_part'\n",
        "second_path = '/content/second_part'\n",
        "\n",
        "\n",
        "detecting_plate(image_path, new_path)\n",
        "split_symbols(new_path, first_path, second_path)\n",
        "left = create_predictions(first_path)\n",
        "left.pop(0)\n",
        "right = create_predictions(second_path)\n",
        "\n",
        "delete_files_in_folder(first_path)\n",
        "delete_files_in_folder(second_path)\n",
        "\n",
        "description = left + right\n",
        "plate_is = ''.join(description)\n",
        "print(plate_is)"
      ],
      "metadata": {
        "id": "XTpGyq9xI_lL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}